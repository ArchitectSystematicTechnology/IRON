This document provides an overview of IronFunctions, how it works, some
open questions, and future directions.

## What is IronFunctions?

IronFunctions allows you to create an API where each endpoint is served by
a Docker container.

In short, it's Iron.io's answer to AWS's combination of API Gateway and Lambda.

## How is IronFunctions different from IronWorker?

They both run Docker containers on demand, but their intended uses are
different. IronWorker is intended more for batch jobs and background tasks,
while IronFunctions hopes to replace API servers and serve HTTP requests via
Docker containers.

Aside from their different goals, their architectures also differ greatly.

IronWorker has several moving parts: the API servers, the queue, and the
runners.

IronFunctions has only one part: the API servers. The servers also run the
Docker containers that serve requests and there is no queue. If we're over
capacity, requests block until capacity becomes available. This means that
monitoring and fast autoscaling is very important to maintain a reliable service.

Also note, however, that this is mainly an issue on the hosted, multitenant
service. On-premise and dedicated users shouldn't have the problem of noisy
neighbors and if they're going over capacity, they need to reserve more
capacity.

## How does IronFunctions work?

First, you have to create an API. The official name for this is yet to be
decided, but other possibilities are "app" or "service". Creating an API also
registers a subdomain {appname}.{project_id}.ironfunctions.com.

After you've created the API, you add routes to it. A route includes a path and
a Docker image name that is to be invoked when a request is sent to the path.

Once you've created an API and added all its routes, you can start sending requests
to the ironfunctions.com subdomain, using the routes you've added. These
requests are redirected to an IronFunctions API server.

When you send a request to a route, the following sequence of events happens:

1. The route's corresponding Docker image is downloaded (if not already
   available locally)
2. A new container runs using that image.
   A. The request headers are sent using environment variables and the request
      body is piped in over standard input.
   B. The container handles the request in whatever way it sees fit. The
      response body is piped out via standard output.
   C. Standard error is for logging. Logs are handled via
      [Logspout](https://github.com/gliderlabs/logspout) and sent to
      [Papertrail](http://papertrailapp.com/). We expose these logs to users
      through the IronFunctions API and they are only kept for a limited time
      (probably 24 hours).
3. The IronFunctions API server responds to the request using the response
   generated by the container.

## Will IronFunctions be open source?

Partly, yes. We will open source the core of IronFunctions and build our
hosted and on-premise products based on that core.

For example, we will likely develop a closed-source dashboard for HUD, and it
will be up to users to figure out what to do with their logs and how to
register subdomains on whatever domain they want.

## Is IronFunctions compatible with AWS Lambda?

It's not exactly compatible, but we can adapt our
[Lambda](https://github.com/iron-io/lambda) containers to also work with
IronFunctions so that Lambdas can be easily converted.

We cannot use our images as they exist now, however, for three reasons:

1. Current images don't read payloads from stdin.
2. Current images don't write responses to stdout.
3. Lambdas potentially write stuff to stdout that's not related to the response at
   all, so our images could do something like internally redirect stdout to stderr.
   Or we can simply say "don't write to stdout unless it's the response".

## Open Questions

### How can we ensure that the first request to an API doesn't have unacceptable latency?

The Docker image has to be downloaded for the first request an IronFunctions API
server receives for a particular API's route, or when the image hasn't been
used in a while. This could take some time.

We're not yet at the point where we're even sure that this is a problem, but it
certainly seems like it could be.

### Should we aim to reuse a container for multiple requests?

Serving only one request per container might alienate users who want to use
JITted languages with long startup times, like Java, due to poor response latencies.
Other JVM languages like Scala or Clojure are even worse. For a data point,
Clojure's "hello world" program takes nearly 500ms on my machine. I'm assuming most
of that is startup time.

However, reusing containers makes things a bit more complicated. We couldn't
use environment variables to pass in request headers, so we'd have to serialize
them into stdin somehow. This makes life harder for everyone.

Handling multiple requests per container isn't something we need for initial
release, but if it's something we want to be able to do in the future we have to
design for it.

### How will users monitor and debug their functions?

There's logging, which is something, but people will probably want more than that.

### Do we need to take extra measures to prevent abuse on the multitenant service?

It's not too hard to imagine someone sucking up all the resources and causing
problems. We may need rate-limiting

## Future Work

Here is a list of work that is probably not needed for the MVP (minimal viable
product), but might be worth thinking about after that:

* Reuse containers for multiple requests. See the unanswered question above.
* Implement a way to avoid bad latencies when we don't already have an image
  cached. (This might be needed for an MVP if it's bad enough.)
* Intelligently route requests to servers. Requests should go to servers that:
  * Have space to serve the request (i.e. aren't serving too many requests
    already)
  * Have the right Docker image downloaded already
  * Have the right container running already (if we reuse containers)
* Give more options for monitoring and debugging.
